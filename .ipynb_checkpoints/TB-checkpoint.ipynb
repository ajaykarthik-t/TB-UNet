{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab9e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D, Activation, GlobalMaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits dataset it into three subfolders: train, val (validation), and test.\n",
    "\n",
    "splitfolders.ratio(r\"C:\\Users\\Ajay\\Desktop\\Tb -U net\\TB_Chest_Radiography_Database\", output=\"output\",\n",
    "    seed=1337, ratio=(.75, .2, .05), group_prefix=None, move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afafe9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('output/')\n",
    "train_dir = 'output/train'\n",
    "val_dir = 'output/val'\n",
    "test_dir = 'output/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a853fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = np.array(sorted([item.name for item in data_dir.glob(\"*\")]))\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666da4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk('output'):\n",
    "  print(f\"{len(dirnames)} folder and {len(filenames)} images in {dirpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_random_image(target_dir, target_class):\n",
    "    target_folder = target_dir + target_class\n",
    "    random_image = random.sample(os.listdir(target_folder), 1)\n",
    "    img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(target_class)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    print(f\"Image Shape : {img.shape}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705ace9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,2):\n",
    "    img_n = view_random_image(target_dir='output/train/', target_class='Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6309e7c-9df5-47ef-b15e-2886ddb8235d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,2):\n",
    "    img_n = view_random_image(target_dir='output/train/', target_class='Tuberculosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01508d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the global random seed.\n",
    "tf.random.set_seed(46)\n",
    "\n",
    "# preprocess data\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.0,\n",
    "                                   rotation_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   vertical_flip=True,\n",
    "                                   horizontal_flip=True)\n",
    "valid_datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5bfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               batch_size=64,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               seed=46)\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(val_dir,\n",
    "                                               batch_size=64,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=False,\n",
    "                                               seed=46)\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                               batch_size=64,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=False,\n",
    "                                               seed=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ee66c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal': 0, 'Tuberculosis': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9986c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=train_data.classes\n",
    "val_y=valid_data.classes\n",
    "test_y=test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d960a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_y.shape: \", train_y.shape)\n",
    "print(\"val_y.shape: \", val_y.shape)\n",
    "print(\"test_y.shape: \", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07576b93-307f-46d5-9e8f-57e2c719c9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 405 images belonging to 2 classes.\n",
      "Found 107 images belonging to 2 classes.\n",
      "Found 28 images belonging to 2 classes.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 224, 224, 64)         1792      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 224, 224, 64)         36928     ['conv2d_18[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 112, 112, 64)         0         ['conv2d_19[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 112, 112, 128)        73856     ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 112, 112, 128)        147584    ['conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 56, 56, 128)          0         ['conv2d_21[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 56, 56, 256)          295168    ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 56, 56, 256)          590080    ['conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 28, 28, 256)          0         ['conv2d_23[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 28, 28, 512)          1180160   ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 28, 28, 512)          2359808   ['conv2d_24[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 28, 28, 512)          0         ['conv2d_25[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 14, 14, 512)          0         ['dropout_2[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 14, 14, 1024)         4719616   ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 14, 14, 1024)         9438208   ['conv2d_26[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 14, 14, 1024)         0         ['conv2d_27[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2D  (None, 28, 28, 512)          2097664   ['dropout_3[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 28, 28, 1024)         0         ['dropout_2[0][0]',           \n",
      " )                                                                   'conv2d_transpose_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 28, 28, 512)          4719104   ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 28, 28, 512)          2359808   ['conv2d_28[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2D  (None, 56, 56, 256)          524544    ['conv2d_29[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 56, 56, 512)          0         ['conv2d_23[0][0]',           \n",
      " )                                                                   'conv2d_transpose_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 56, 56, 256)          1179904   ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 56, 56, 256)          590080    ['conv2d_30[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2D  (None, 112, 112, 128)        131200    ['conv2d_31[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 112, 112, 256)        0         ['conv2d_21[0][0]',           \n",
      " )                                                                   'conv2d_transpose_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 112, 112, 128)        295040    ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 112, 112, 128)        147584    ['conv2d_32[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2D  (None, 224, 224, 64)         32832     ['conv2d_33[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 224, 224, 128)        0         ['conv2d_19[0][0]',           \n",
      " )                                                                   'conv2d_transpose_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 224, 224, 64)         73792     ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 224, 224, 64)         36928     ['conv2d_34[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 64)                   0         ['conv2d_35[0][0]']           \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  16640     ['global_average_pooling2d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 256)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 2)                    514       ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31048834 (118.44 MB)\n",
      "Trainable params: 31048834 (118.44 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Training U-Net Model...\n",
      "WARNING:tensorflow:From C:\\Users\\Ajay\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ajay\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      " 3/13 [=====>........................] - ETA: 20:06 - loss: 0.6874 - accuracy: 0.5521"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Directories\n",
    "train_dir = 'output/train'\n",
    "val_dir = 'output/val'\n",
    "test_dir = 'output/test'\n",
    "\n",
    "# Image dimensions and batch size\n",
    "input_shape = (224, 224, 3)\n",
    "batch_size = 32\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Function to create U-Net model\n",
    "def create_unet_model(input_shape, num_classes):\n",
    "    # Define inputs\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Contracting path (encoder)\n",
    "    # Block 1\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    # Block 2\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    # Block 3\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    # Block 4\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    \n",
    "    # Middle\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    # Expansive path (decoder)\n",
    "    # Block 6\n",
    "    up6 = Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(drop5)\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    # Block 7\n",
    "    up7 = Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "    \n",
    "    # Block 8\n",
    "    up8 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "    \n",
    "    # Block 9\n",
    "    up9 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "    \n",
    "    # Output layer for classification (modified for multi-class classification)\n",
    "    # Global average pooling to convert feature maps to features\n",
    "    gap = tf.keras.layers.GlobalAveragePooling2D()(conv9)\n",
    "    \n",
    "    # Dense layers for classification\n",
    "    dense1 = Dense(256, activation='relu')(gap)\n",
    "    dropout = Dropout(0.5)(dense1)\n",
    "    outputs = Dense(num_classes, activation='softmax')(dropout)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Create and compile the U-Net model\n",
    "unet_model = create_unet_model(input_shape, train_data.num_classes)\n",
    "unet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "unet_model.summary()\n",
    "\n",
    "# Train the model\n",
    "print(\"Training U-Net Model...\")\n",
    "history = unet_model.fit(\n",
    "    train_data,\n",
    "    epochs=1,\n",
    "    validation_data=val_data\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "unet_model.save(\"unet_model.h5\")\n",
    "print(\"U-Net Model saved as 'unet_model.h5'.\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"Evaluating model on test data...\")\n",
    "test_results = unet_model.evaluate(test_data)\n",
    "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c3943e-178a-4c3d-bb2d-baa67867402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 405 images belonging to 2 classes.\n",
      "Found 107 images belonging to 2 classes.\n",
      "Found 28 images belonging to 2 classes.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 128, 128, 32)         896       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 128, 128, 32)         128       ['conv2d_36[0][0]']           \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 64, 64, 32)           0         ['batch_normalization[0][0]'] \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 64, 64, 64)           18496     ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 64, 64, 64)           256       ['conv2d_37[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 32, 32, 64)           0         ['batch_normalization_1[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (None, 32, 32, 128)          73856     ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 32, 32, 128)          512       ['conv2d_38[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, 16, 16, 128)          0         ['batch_normalization_2[0][0]'\n",
      " ng2D)                                                              ]                             \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (None, 16, 16, 256)          295168    ['max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 16, 16, 256)          1024      ['conv2d_39[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 16, 16, 256)          0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2D  (None, 32, 32, 128)          131200    ['dropout_5[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 32, 32, 256)          0         ['batch_normalization_2[0][0]'\n",
      " )                                                                  , 'conv2d_transpose_8[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (None, 32, 32, 128)          295040    ['concatenate_8[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 32, 32, 128)          512       ['conv2d_40[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2D  (None, 64, 64, 64)           32832     ['batch_normalization_4[0][0]'\n",
      " Transpose)                                                         ]                             \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate  (None, 64, 64, 128)          0         ['batch_normalization_1[0][0]'\n",
      " )                                                                  , 'conv2d_transpose_9[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (None, 64, 64, 64)           73792     ['concatenate_9[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 64, 64, 64)           256       ['conv2d_41[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2  (None, 128, 128, 32)         8224      ['batch_normalization_5[0][0]'\n",
      " DTranspose)                                                        ]                             \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 128, 128, 64)         0         ['batch_normalization[0][0]', \n",
      " e)                                                                  'conv2d_transpose_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (None, 128, 128, 32)         18464     ['concatenate_10[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 128, 128, 32)         128       ['conv2d_42[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 32)                   0         ['batch_normalization_6[0][0]'\n",
      "  (GlobalAveragePooling2D)                                          ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  4224      ['global_average_pooling2d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 128)                  0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2)                    258       ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 955266 (3.64 MB)\n",
      "Trainable params: 953858 (3.64 MB)\n",
      "Non-trainable params: 1408 (5.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Training Lightweight U-Net Model...\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 35s 4s/step - loss: 0.5459 - accuracy: 0.7679 - val_loss: 0.6909 - val_accuracy: 0.5981 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 31s 4s/step - loss: 0.3716 - accuracy: 0.8494 - val_loss: 0.7801 - val_accuracy: 0.4019 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.3417 - accuracy: 0.8568 - val_loss: 0.7008 - val_accuracy: 0.5981 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2941 - accuracy: 0.8716 - val_loss: 0.8179 - val_accuracy: 0.5981 - lr: 5.0000e-04\n",
      "Lightweight U-Net Model saved as 'lightweight_unet_model.h5'.\n",
      "Evaluating model on test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajay\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 727ms/step - loss: 0.6868 - accuracy: 0.7143\n",
      "Test Loss: 0.6868\n",
      "Test Accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "# Directories\n",
    "train_dir = 'output/train'\n",
    "val_dir = 'output/val'\n",
    "test_dir = 'output/test'\n",
    "\n",
    "# Image dimensions and batch size\n",
    "input_shape = (128, 128, 3)  # Reduced image size for faster processing\n",
    "batch_size = 64  # Increased batch size if your GPU can handle it\n",
    "\n",
    "# Data generators with additional augmentation for better generalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),  # Reduced image size\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(128, 128),  # Reduced image size\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),  # Reduced image size\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Function to create lightweight U-Net model\n",
    "def create_lightweight_unet(input_shape, num_classes):\n",
    "    # Define inputs\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Contracting path (encoder) - Reduced filters\n",
    "    # Block 1\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)  # Reduced from 64\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    # Block 2\n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)  # Reduced from 128\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    # Block 3\n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)  # Reduced from 256\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    # Middle (bottleneck)\n",
    "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(pool3)  # Reduced from 512\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    drop4 = Dropout(0.3)(conv4)  # Reduced dropout rate\n",
    "    \n",
    "    # Expansive path (decoder) - Reduced filters\n",
    "    # Block 5\n",
    "    up5 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(drop4)\n",
    "    merge5 = concatenate([conv3, up5], axis=3)\n",
    "    conv5 = Conv2D(128, 3, activation='relu', padding='same')(merge5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "    # Block 6\n",
    "    up6 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv5)\n",
    "    merge6 = concatenate([conv2, up6], axis=3)\n",
    "    conv6 = Conv2D(64, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "    # Block 7\n",
    "    up7 = Conv2DTranspose(32, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    merge7 = concatenate([conv1, up7], axis=3)\n",
    "    conv7 = Conv2D(32, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "    # Global average pooling for classification\n",
    "    gap = tf.keras.layers.GlobalAveragePooling2D()(conv7)\n",
    "    \n",
    "    # Dense layers for classification\n",
    "    dense1 = Dense(128, activation='relu')(gap)  # Reduced from 256\n",
    "    dropout = Dropout(0.3)(dense1)  # Reduced dropout\n",
    "    outputs = Dense(num_classes, activation='softmax')(dropout)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Create and compile the lightweight U-Net model\n",
    "unet_model = create_lightweight_unet(input_shape, train_data.num_classes)\n",
    "unet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "unet_model.summary()\n",
    "\n",
    "# Define callbacks to speed up training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.00001)\n",
    "]\n",
    "\n",
    "# Train the model with fewer epochs and callbacks\n",
    "print(\"Training Lightweight U-Net Model...\")\n",
    "history = unet_model.fit(\n",
    "    train_data,\n",
    "    epochs=5,  # Reduced number of epochs\n",
    "    validation_data=val_data,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "unet_model.save(\"lightweight_unet_model.h5\")\n",
    "print(\"Lightweight U-Net Model saved as 'lightweight_unet_model.h5'.\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"Evaluating model on test data...\")\n",
    "test_results = unet_model.evaluate(test_data)\n",
    "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9a596-3c6d-4dda-92fc-535c121b308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "\n",
    "class SimpleTBPredictor:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Tuberculosis Detector\")\n",
    "        self.root.geometry(\"800x600\")\n",
    "        self.root.configure(bg=\"#f0f0f0\")\n",
    "        \n",
    "        # Class indices\n",
    "        self.class_indices = {'Normal': 0, 'Tuberculosis': 1}\n",
    "        self.class_names = {v: k for k, v in self.class_indices.items()}\n",
    "        \n",
    "        # Load model automatically\n",
    "        try:\n",
    "            self.model = load_model(\"lightweight_unet_model.h5\")\n",
    "            self.status_var = tk.StringVar()\n",
    "            self.status_var.set(\"Model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            self.status_var = tk.StringVar()\n",
    "            self.status_var.set(f\"Error loading model: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to load model: {str(e)}\")\n",
    "        \n",
    "        # Main frame\n",
    "        main_frame = tk.Frame(root, bg=\"#f0f0f0\")\n",
    "        main_frame.pack(pady=10, fill=\"both\", expand=True)\n",
    "        \n",
    "        # Upload button\n",
    "        self.upload_btn = tk.Button(main_frame, text=\"Upload Image\", command=self.upload_image,\n",
    "                                    bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12), padx=20, pady=10)\n",
    "        self.upload_btn.pack(pady=20)\n",
    "        \n",
    "        # Display frame (image and result side by side)\n",
    "        display_frame = tk.Frame(main_frame, bg=\"#f0f0f0\")\n",
    "        display_frame.pack(fill=\"both\", expand=True, padx=20)\n",
    "        \n",
    "        # Image display\n",
    "        self.image_frame = tk.Frame(display_frame, bg=\"white\", width=350, height=350)\n",
    "        self.image_frame.pack(side=tk.LEFT, padx=10, fill=\"both\", expand=True)\n",
    "        self.image_label = tk.Label(self.image_frame, bg=\"white\")\n",
    "        self.image_label.pack(fill=\"both\", expand=True)\n",
    "        \n",
    "        # Results display\n",
    "        self.result_frame = tk.Frame(display_frame, bg=\"#f0f0f0\", width=350)\n",
    "        self.result_frame.pack(side=tk.RIGHT, padx=10, fill=\"both\", expand=True)\n",
    "        \n",
    "        # Result label\n",
    "        self.result_label = tk.Label(self.result_frame, text=\"No prediction yet\", \n",
    "                                    font=(\"Arial\", 16, \"bold\"), bg=\"#f0f0f0\")\n",
    "        self.result_label.pack(pady=20)\n",
    "        \n",
    "        # Result details frame\n",
    "        self.details_frame = tk.Frame(self.result_frame, bg=\"#f0f0f0\")\n",
    "        self.details_frame.pack(fill=\"both\", expand=True)\n",
    "        \n",
    "        # Status bar\n",
    "        status_bar = tk.Label(root, textvariable=self.status_var, bd=1, relief=tk.SUNKEN, anchor=tk.W)\n",
    "        status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "    \n",
    "    def upload_image(self):\n",
    "        \"\"\"Upload and process an image\"\"\"\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select Image\", \n",
    "            filetypes=((\"Image files\", \"*.jpg *.jpeg *.png\"), (\"All files\", \"*.*\"))\n",
    "        )\n",
    "        \n",
    "        if not file_path:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Display image\n",
    "            self.display_image(file_path)\n",
    "            \n",
    "            # Process image and make prediction\n",
    "            self.predict_image(file_path)\n",
    "        except Exception as e:\n",
    "            self.status_var.set(f\"Error: {str(e)}\")\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "    \n",
    "    def display_image(self, img_path):\n",
    "        \"\"\"Display the selected image\"\"\"\n",
    "        # Open and resize image for display\n",
    "        img = Image.open(img_path)\n",
    "        img.thumbnail((350, 350))\n",
    "        \n",
    "        # Convert to PhotoImage\n",
    "        photo_img = ImageTk.PhotoImage(img)\n",
    "        \n",
    "        # Update image label\n",
    "        self.image_label.config(image=photo_img)\n",
    "        self.image_label.image = photo_img  # Keep reference\n",
    "    \n",
    "    def predict_image(self, img_path):\n",
    "        \"\"\"Process image and display prediction results\"\"\"\n",
    "        # Clear previous results\n",
    "        for widget in self.details_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "        \n",
    "        # Preprocess image\n",
    "        img = image.load_img(img_path, target_size=(128, 128))  # Match model input size\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = img_array / 255.0  # Normalize\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "        \n",
    "        # Make prediction\n",
    "        predictions = self.model.predict(img_array)\n",
    "        predicted_class_idx = np.argmax(predictions[0])\n",
    "        predicted_class = self.class_names[predicted_class_idx]\n",
    "        confidence = predictions[0][predicted_class_idx] * 100\n",
    "        \n",
    "        # Update result label\n",
    "        if predicted_class == \"Normal\":\n",
    "            self.result_label.config(text=\"NORMAL\", fg=\"#4CAF50\")\n",
    "        else:\n",
    "            self.result_label.config(text=\"TUBERCULOSIS DETECTED\", fg=\"#F44336\")\n",
    "        \n",
    "        # Create confidence visualization\n",
    "        self.create_confidence_chart(predictions[0])\n",
    "        \n",
    "        # Update status\n",
    "        self.status_var.set(f\"Prediction: {predicted_class} with {confidence:.2f}% confidence\")\n",
    "    \n",
    "    def create_confidence_chart(self, probabilities):\n",
    "        \"\"\"Create and display confidence visualization\"\"\"\n",
    "        # Create figure for the chart\n",
    "        fig, ax = plt.subplots(figsize=(4, 3))\n",
    "        \n",
    "        # Bar chart data\n",
    "        classes = list(self.class_names.values())\n",
    "        colors = ['#4CAF50', '#F44336']  # Green for Normal, Red for TB\n",
    "        \n",
    "        # Create bar chart\n",
    "        bars = ax.bar(classes, probabilities*100, color=colors)\n",
    "        \n",
    "        # Customize appearance\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_ylabel('Confidence (%)')\n",
    "        ax.set_title('Prediction Confidence')\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.1f}%',\n",
    "                      xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                      xytext=(0, 3),\n",
    "                      textcoords=\"offset points\",\n",
    "                      ha='center', va='bottom')\n",
    "        \n",
    "        # Create canvas in the details frame\n",
    "        canvas = FigureCanvasTkAgg(fig, master=self.details_frame)\n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True, pady=10)\n",
    "\n",
    "# Run the application\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = SimpleTBPredictor(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d1a5a-df61-4319-83e2-75145ab6f12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
